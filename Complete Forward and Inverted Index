import os
import time
import json 
import nltk
import re
from nltk.corpus import wordnet
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from collections import Counter
from nltk.stem.snowball import SnowballStemmer


snow_stemmer = SnowballStemmer(language='english')


#global data:
docID = 0        
titleID = 0         #assign unique ids to word, doc and title
wordID = 0
finaldocs = {}
lexicon= {}         #dictionary for lexicon of article content
titlelex = {}       #lexicon for titles
fwdIndexContent = {}
fwdIndexTitle = {}
invertedIndexContent = {}
invertedIndexTitle = {}     
stop_words = set(stopwords.words('english')) 
stopwords_dict = Counter(stop_words)

#FUNCTIONS:

def stemming(wordlist): 
  wordsfinal = []
  for word in wordlist:
    wordsfinal.append(snow_stemmer.stem(word))
  return wordsfinal

#titlewords = ""
def tokenize(dict, name):
    tokens =[]
    if name=="content":
        content = dict["content"]
    else:
        content = dict["title"]
    tokens.extend(word_tokenize(content)) #list of lists
    noStopWords = []
    for word in tokens:
        word = word.lower()
        if (word.isalnum() and word.casefold() not in stop_words):
            noStopWords.append(word)
    final = stemming(noStopWords)
    return final

def createlexicon(wordlist, name):
    if name=="content":
        global wordID
        for word in wordlist:
            if lexicon.get(word) is not None:
                pass
            else:
                lexicon.update({word:wordID})
                wordID+=1
    else:
        global titleID
        for word in wordlist:
            if titlelex.get(word) is not None:
                pass
            else:
                titlelex.update({word:wordID})
                wordID+=1
    

def createFwdIndex(content, name):
    global fwdIndexContent
    global fwdIndexTitle
    global docID
    innerdict = {}
    if name == "content":
        for index in range (len(content)):   #accesses each word of content 
            counter = 0
            ID = lexicon.get(content[index])
            #position = index
            if innerdict.get(ID) is None:
                counter+=1
                innerdict.update({ID:counter})
            else:
                counter=innerdict.get(ID)
                counter+=1
                innerdict[ID]=counter         
        fwdIndexContent.update({docID-1:innerdict})
    else:
        for index in range (len(content)):   #accesses each word of content 
            counter = 0
            ID = titlelex.get(content[index])
            position = index
            if innerdict.get(ID) is None:
                counter+=1
                innerdict.update({ID:counter})
            else:
                counter=innerdict.get(ID)
                counter+=1
                innerdict[ID]=counter       
        fwdIndexTitle.update({docID-1:innerdict})
        
def createInvertedIndex(name):
    if name=="content":
        for keys in fwdIndexContent: #each key: docID
            inner = fwdIndexContent.get(keys)#dict of each doc, with words and their hits 
            for key2 in inner: #WORDS THAT ARE IN THE DOCUMENT
                if invertedIndexContent.get(key2) is not None:
                    invertedIndexContent[key2].append(keys)
                else:
                    list1 = [keys]
                    invertedIndexContent.update({key2:list1})
    else:
        for keys in fwdIndexTitle: #each key: docID
            inner = fwdIndexTitle.get(keys)#dict of each doc, with words + positions 
            for key2 in inner: #WORDS THAT ARE IN THE DOCUMENT
                if invertedIndexTitle.get(key2) is not None:
                    invertedIndexTitle[key2].append(keys)
                else:
                    list1 = [keys]
                    invertedIndexTitle.update({key2:list1})


filename1 = "fwdIndexContentFinal.json"     
filename2 = "lexiconFinal.json"         #names of final files to be passed to function
filename3 = "titlelexFinal.json"
filename4 = "invertedIndexContentFinal.json"
filename5 = "fwdIndexTitleFinal.json"
filename6 = "invertedIndexTitleFinal.json"
filename7 = "docIndexFinal.json"

def writeFiles(dict, filename):
    filename = finalpath + "\\" + filename
    json_object = json.dumps(dict)
    with open(filename, "w", encoding='utf-8') as finalfile:
        finalfile.write(json_object)

docindex = {}
def createDocIndex(dictionary, filenumber,docID):
        global docindex
        docinfo = []
        docinfo.append(dictionary.get("url"))
        docinfo.append(dictionary.get("title"))
        docinfo.append(filenumber)
        docindex.update({docID:docinfo})


##SPECIFYING PATHS OF DATA:

sourcepath = "E:\samplef" #folder containing data files
finalpath = "E:\indexfilesfinal"  #PATH for folder where final, tokenized content of docs will be stored



#Processing:

filenum = -1

start = time.time()
for file in os.listdir(sourcepath): #369, 911truth
    file = sourcepath+"\\"+file
    myfile = open(file)
    data = json.load(myfile) #returns a list(of dictionaries?)
    filenum+=1
    for dict in data: #each dictionary represents ONE article
        createDocIndex(dict, filenum,docID)

        # TOKENIZING CONTENT:
        finalWords = tokenize(dict, "content")
        
        # TOKENIZING TITLES:
        finalTitles = tokenize(dict, "title")

        docID+=1

        #CREATING lexicons:
        createlexicon(finalWords, "content")
        createlexicon(finalTitles, "title")  
        createFwdIndex(finalWords,"content")
        createFwdIndex(finalTitles, "title")
    myfile.close()


#CREATING INVERTED INDEX:
createInvertedIndex("content")
createInvertedIndex("title")


writeFiles(fwdIndexContent, filename1)
writeFiles(lexicon, filename2)
writeFiles(titlelex, filename3)
writeFiles(invertedIndexContent,filename4)
writeFiles(fwdIndexTitle,filename5)
writeFiles(invertedIndexTitle,filename6)
writeFiles(docindex, filename7)
